{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6_Fqcgn299n",
        "outputId": "d2c11eb4-56f4-469d-ad46-a64ae9c05a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 53.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=3b404c29f72a2288787f9d8cab0e0cbfe9b53e006ba086709533f517285ea554\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0A8Z2PmA2-df"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4ExJE2zi3B-U"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  spark = SparkSession.builder.appName('Jobathon').master('local').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fApwwwEk3E9Z",
        "outputId": "95f228b1-7ae7-4c16-e0e6-bc20ada6b454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8Hvvx6Vk3T6m"
      },
      "outputs": [],
      "source": [
        "df_clickstream = '/content/drive/My Drive/jobathon_sample_data/jobathon_click_data.json'\n",
        "user_mapping = '/content/drive/My Drive/jobathon_sample_data/jobathon_login_data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "98Dab01-3Glg"
      },
      "outputs": [],
      "source": [
        "def sample_function(spark, s3_clickstream_path, s3_login_path):\n",
        "    \n",
        "    df_clickstream =  spark.read.format(\"json\").load(s3_clickstream_path)\n",
        "    \n",
        "    user_mapping =  spark.read.format(\"csv\").option(\"header\",True).load(s3_login_path)\n",
        "\n",
        "    df_clickstream = df_clickstream.withColumn('current_page_url',col('client_side_data.current_page_url')).drop('client_side_data')\n",
        "\n",
        "    df_clickstream = user_mapping.join(df_clickstream, (user_mapping.session_id == df_clickstream.session_id)&(to_date(user_mapping.login_date_time)==to_date(df_clickstream.event_date_time)),'right').drop(user_mapping.session_id)\n",
        "\n",
        "    df_clickstream = df_clickstream.fillna(value='Unregister',subset=[\"user_id\"])\n",
        "\n",
        "    df_clickstream = df_clickstream.withColumn('logged_in', when((df_clickstream.user_id == 'Unregister'),lit('0')).otherwise(lit('1'))) \\\n",
        "                            .withColumn('click', when((df_clickstream.event_type == 'click'),lit('1')).otherwise(lit('0'))) \\\n",
        "                            .withColumn('pageload', when((df_clickstream.event_type == 'pageload'),lit('1')).otherwise(lit('0'))) \\\n",
        "                            .withColumn('current_date',substring(col(\"event_date_time\"),1,10))\n",
        "\n",
        "    for_data = df_clickstream.groupBy('current_date','user_id','browser_id').agg(min(to_timestamp(df_clickstream.event_date_time)).alias('First')).select('user_id','First','browser_id','current_date')\n",
        "    \n",
        "    for_data = for_data.join(df_clickstream.select('current_page_url','event_date_time'), (for_data['first'] == df_clickstream['event_date_time'])&(for_data['user_id']==df_clickstream['user_id'])&(for_data['browser_id']==df_clickstream['browser_id']),'left')\n",
        "    \n",
        "    df_clickstream = df_clickstream.join(for_data,(for_data['current_date'] == df_clickstream['current_date'])&(for_data['user_id']==df_clickstream['user_id'])&(for_data['browser_id']==df_clickstream['browser_id']),'left')\\\n",
        "                                    .drop(for_data.current_date)\\\n",
        "                                    .drop(for_data.user_id)\\\n",
        "                                    .drop(for_data.browser_id)\\\n",
        "                                    .drop(for_data.current_page_url)     \n",
        "\n",
        "    df_clickstream = df_clickstream.withColumnRenamed('current_page_url','first_url')\n",
        "\n",
        "    df_clickstream = df_clickstream.select('*').groupBy('current_date','browser_id','user_id','logged_in','first_url').agg(sum(df_clickstream.click).alias('number_of_clicks'),sum(df_clickstream.pageload).alias('number_of_pageloads'))\n",
        "    \n",
        "    df_clickstream = df_clickstream.replace(\"Unregister\", None ,subset = [\"user_id\"])\n",
        "\n",
        "    df_union = df_clickstream.select(\"current_date\",\"browser_id\",\"user_id\",\"logged_in\",\"first_url\",\"number_of_clicks\",\"number_of_pageloads\")\n",
        "\n",
        "    df_union.createOrReplaceTempView(\"df_union_tbl\")\n",
        "    \n",
        "    df_result = spark.sql(\"select * from df_union_tbl\")\n",
        "    \n",
        "    # Return your final spark df\"\"\"\n",
        "    return df_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iO62axT3y6_",
        "outputId": "5ba3e5dc-e421-47e2-a51a-76f37fabb70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------------+-------+---------+--------------------+----------------+-------------------+\n",
            "|current_date|          browser_id|user_id|logged_in|           first_url|number_of_clicks|number_of_pageloads|\n",
            "+------------+--------------------+-------+---------+--------------------+----------------+-------------------+\n",
            "|  2022-07-31|1DSHqOeZmWRLijQx9...|   null|        0|https://www.gosho...|             4.0|                0.0|\n",
            "|  2022-07-31|1j5R1PQuTDcHXcd52...|   null|        0|https://www.gosho...|            24.0|                2.0|\n",
            "|  2022-07-31|1r3shTM5PCT83mpWD...|   null|        0|https://www.gosho...|             2.0|                0.0|\n",
            "|  2022-07-31|24vwqAsGWbb2CkiWB...|   null|        0|https://www.gosho...|             0.0|                1.0|\n",
            "|  2022-07-31|27ODeTm2X9Nhrgs1a...|   null|        0|https://www.gosho...|             1.0|                0.0|\n",
            "+------------+--------------------+-------+---------+--------------------+----------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample_function(spark,df_clickstream,user_mapping).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUVG0eiCnrRr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}